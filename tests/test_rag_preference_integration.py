"""
Integration tests for RAG system with preference document scenarios.

Tests the enhanced RAG system's ability to handle preference-related questions
with various document availability scenarios (complete, partial, missing).
"""

import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch
from uuid import uuid4
from datetime import datetime

from rag.question_processor import QuestionProcessor, ProcessedQuestion, QuestionCategory, QuestionIntent
from rag.context_builder import ContextBuilder, PromptTemplate, RetrievedDocument
from rag.response_generator import ResponseGenerator, GeneratedResponse, ResponseQuality
from etl.vector_embedder import VectorEmbedder
from database.vector_search import VectorSearchService, SearchResult
from database.models import ChatDocument


class TestRAGPreferenceIntegration:
    """Test RAG system integration with preference document scenarios."""
    
    @pytest.fixture
    def mock_vector_embedder(self):
        """Mock vector embedder for testing."""
        embedder = Mock(spec=VectorEmbedder)
        embedder.generate_embedding = AsyncMock(return_value=[0.1, 0.2, 0.3] * 100)  # 300-dim vector
        return embedder
    
    @pytest.fixture
    def mock_vector_search(self):
        """Mock vector search service for testing."""
        search_service = Mock(spec=VectorSearchService)
        search_service.similarity_search = AsyncMock()
        return search_service
    
    @pytest.fixture
    def question_processor(self, mock_vector_embedder):
        """Question processor instance for testing."""
        return QuestionProcessor(mock_vector_embedder)
    
    @pytest.fixture
    def context_builder(self, mock_vector_search):
        """Context builder instance for testing."""
        return ContextBuilder(mock_vector_search)
    
    @pytest.fixture
    def response_generator(self):
        """Response generator instance for testing."""
        with patch.dict('os.environ', {'GEMINI_API_KEY': 'test-key'}):
            generator = ResponseGenerator()
            # Mock the Gemini API call
            generator._call_gemini_api = AsyncMock()
            return generator
    
    def create_preference_document(self, doc_type="PREFERENCE_ANALYSIS", completion_level="complete", 
                                 sub_type="overview", content=None, summary="ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼"):
        """Helper to create preference documents for testing."""
        if content is None:
            content = {
                "completion_status": "ì™„ë£Œ" if completion_level == "complete" else "ë¶€ë¶„ ì™„ë£Œ",
                "preferences": [
                    {"preference_name": "ì°½ì˜ì  í™œë™", "rank": 1, "description": "ì˜ˆìˆ ì ì´ê³  ì°½ì˜ì ì¸ í™œë™ì„ ì„ í˜¸"},
                    {"preference_name": "ë¶„ì„ì  ì‚¬ê³ ", "rank": 2, "description": "ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ë¶„ì„ì„ ì„ í˜¸"}
                ] if completion_level != "missing" else [],
                "stats": {
                    "total_image_count": 50,
                    "response_count": 45,
                    "response_rate": 90
                } if completion_level == "complete" else None
            }
        
        return ChatDocument(
            doc_id=uuid4(),
            user_id=uuid4(),
            doc_type=doc_type,
            content=content,
            summary_text=summary,
            metadata={
                "completion_level": completion_level,
                "sub_type": sub_type,
                "created_at": datetime.now().isoformat()
            },
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
    
    def create_retrieved_document(self, document, similarity_score=0.8, relevance_score=0.9):
        """Helper to create retrieved document wrapper."""
        return RetrievedDocument(
            document=document,
            similarity_score=similarity_score,
            relevance_score=relevance_score,
            content_summary=document.summary_text,
            key_points=["ì£¼ìš” ì„ í˜¸ë„ ë¶„ì„", "ê°œì¸ë³„ ë§ì¶¤ ê²°ê³¼"]
        )

    @pytest.mark.asyncio
    async def test_preference_question_detection(self, question_processor):
        """Test that preference-related questions are correctly detected."""
        test_cases = [
            ("ë‚´ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ ì•Œë ¤ì¤˜", QuestionCategory.PREFERENCE_ANALYSIS),
            ("ì´ë¯¸ì§€ ì„ í˜¸ë„ëŠ” ì–´ë–»ê²Œ ë‚˜ì™”ì–´?", QuestionCategory.PREFERENCE_ANALYSIS),
            ("ë‚˜ëŠ” ì–´ë–¤ ê²ƒì„ ì¢‹ì•„í•˜ë‚˜ìš”?", QuestionCategory.PREFERENCE_ANALYSIS),
            ("ì„ í˜¸í•˜ëŠ” í™œë™ì´ ë­ì•¼?", QuestionCategory.PREFERENCE_ANALYSIS),
            ("ì·¨í–¥ ë¶„ì„ ê²°ê³¼ ë³´ì—¬ì¤˜", QuestionCategory.PREFERENCE_ANALYSIS),
            ("ê´€ì‹¬ì‚¬ê°€ ë­”ì§€ ì•Œë ¤ì¤˜", QuestionCategory.PREFERENCE_ANALYSIS),
            ("ë‚´ ì„±ê²©ì€ ì–´ë•Œ?", QuestionCategory.PERSONALITY),  # Should not be preference
        ]
        
        for question, expected_category in test_cases:
            processed = await question_processor.process_question(question, "test_user")
            assert processed.category == expected_category, f"Question '{question}' should be categorized as {expected_category}"

    @pytest.mark.asyncio
    async def test_complete_preference_documents_context(self, context_builder, mock_vector_search):
        """Test context building with complete preference documents."""
        # Create complete preference documents
        complete_doc = self.create_preference_document(
            completion_level="complete",
            sub_type="overview",
            content={
                "completion_status": "ì™„ë£Œ",
                "preference_count": 5,
                "job_count": 12,
                "top_preferences": ["ì°½ì˜ì  í™œë™", "ë¶„ì„ì  ì‚¬ê³ ", "í˜‘ë ¥ì  ì—…ë¬´"],
                "quality_score": 0.9,
                "stats": {"response_rate": 95}
            }
        )
        
        retrieved_docs = [self.create_retrieved_document(complete_doc)]
        
        # Mock vector search to return complete documents
        mock_vector_search.similarity_search.return_value = [
            SearchResult(document=complete_doc, similarity_score=0.9, rank=1, search_metadata={})
        ]
        
        # Create processed question
        processed_question = ProcessedQuestion(
            original_text="ë‚´ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ ì•Œë ¤ì¤˜",
            cleaned_text="ë‚´ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ ì•Œë ¤ì¤˜?",
            category=QuestionCategory.PREFERENCE_ANALYSIS,
            intent=QuestionIntent.EXPLAIN,
            embedding_vector=[0.1] * 300,
            keywords=["ì„ í˜¸ë„", "ë¶„ì„", "ê²°ê³¼"],
            confidence_score=0.8,
            requires_specific_docs=["PREFERENCE_ANALYSIS"]
        )
        
        # Build context
        context = await context_builder.build_context(processed_question, "test_user")
        
        # Verify template selection
        assert context.prompt_template == PromptTemplate.PREFERENCE_EXPLAIN
        assert len(context.retrieved_documents) == 1
        assert "ì™„ë£Œ" in context.formatted_prompt
        assert "ì„ í˜¸ë„ ë¶„ì„ ì „ë¬¸ê°€" in context.formatted_prompt

    @pytest.mark.asyncio
    async def test_partial_preference_documents_context(self, context_builder, mock_vector_search):
        """Test context building with partial preference documents."""
        # Create partial preference document
        partial_doc = self.create_preference_document(
            completion_level="partial",
            sub_type="partial_data",
            content={
                "completion_status": "ë¶€ë¶„ ì™„ë£Œ",
                "stats": None,  # Missing stats
                "preferences": [{"preference_name": "ì°½ì˜ì  í™œë™", "rank": 1}],
                "jobs": None  # Missing jobs
            },
            summary="ì„ í˜¸ë„ ë¶„ì„: ì¼ë¶€ ë°ì´í„°ë§Œ ì¤€ë¹„ë¨"
        )
        
        retrieved_docs = [self.create_retrieved_document(partial_doc)]
        
        # Mock vector search
        mock_vector_search.similarity_search.return_value = [
            SearchResult(document=partial_doc, similarity_score=0.7, rank=1, search_metadata={})
        ]
        
        processed_question = ProcessedQuestion(
            original_text="ë‚´ ì„ í˜¸ë„ëŠ” ì–´ë–»ê²Œ ë‚˜ì™”ì–´?",
            cleaned_text="ë‚´ ì„ í˜¸ë„ëŠ” ì–´ë–»ê²Œ ë‚˜ì™”ì–´?",
            category=QuestionCategory.PREFERENCE_ANALYSIS,
            intent=QuestionIntent.EXPLAIN,
            embedding_vector=[0.1] * 300,
            keywords=["ì„ í˜¸ë„"],
            confidence_score=0.8,
            requires_specific_docs=["PREFERENCE_ANALYSIS"]
        )
        
        context = await context_builder.build_context(processed_question, "test_user")
        
        # Verify partial template selection
        assert context.prompt_template == PromptTemplate.PREFERENCE_PARTIAL
        assert "ë¶€ë¶„ì ìœ¼ë¡œë§Œ ì¤€ë¹„ëœ" in context.formatted_prompt
        assert "âš ï¸ ì£¼ì˜" in context.formatted_prompt

    @pytest.mark.asyncio
    async def test_missing_preference_documents_context(self, context_builder, mock_vector_search):
        """Test context building when preference documents are missing."""
        # Create non-preference documents (personality, thinking skills)
        personality_doc = ChatDocument(
            doc_id=uuid4(),
            user_id=uuid4(),
            doc_type="PERSONALITY_PROFILE",
            content={"primary_tendency": {"name": "ì°½ì˜í˜•"}},
            summary_text="ì„±ê²© ë¶„ì„ ê²°ê³¼",
            metadata={},
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        # Mock vector search to return non-preference documents
        mock_vector_search.similarity_search.return_value = [
            SearchResult(document=personality_doc, similarity_score=0.6, rank=1, search_metadata={})
        ]
        
        processed_question = ProcessedQuestion(
            original_text="ë‚´ ì´ë¯¸ì§€ ì„ í˜¸ë„ ì•Œë ¤ì¤˜",
            cleaned_text="ë‚´ ì´ë¯¸ì§€ ì„ í˜¸ë„ ì•Œë ¤ì¤˜?",
            category=QuestionCategory.PREFERENCE_ANALYSIS,
            intent=QuestionIntent.EXPLAIN,
            embedding_vector=[0.1] * 300,
            keywords=["ì´ë¯¸ì§€", "ì„ í˜¸ë„"],
            confidence_score=0.8,
            requires_specific_docs=["PREFERENCE_ANALYSIS"]
        )
        
        context = await context_builder.build_context(processed_question, "test_user")
        
        # Verify missing template selection
        assert context.prompt_template == PromptTemplate.PREFERENCE_MISSING
        assert "ë°ì´í„°ê°€ ì—†ëŠ” ìƒí™©" in context.formatted_prompt
        assert "ë‹¤ë¥¸ ê²€ì‚¬ ê²°ê³¼" in context.formatted_prompt

    @pytest.mark.asyncio
    async def test_preference_response_validation_complete_data(self, response_generator, context_builder, mock_vector_search):
        """Test response validation with complete preference data."""
        # Setup complete preference context
        complete_doc = self.create_preference_document(completion_level="complete")
        mock_vector_search.similarity_search.return_value = [
            SearchResult(document=complete_doc, similarity_score=0.9, rank=1, search_metadata={})
        ]
        
        processed_question = ProcessedQuestion(
            original_text="ë‚´ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ ì•Œë ¤ì¤˜",
            cleaned_text="ë‚´ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ ì•Œë ¤ì¤˜?",
            category=QuestionCategory.PREFERENCE_ANALYSIS,
            intent=QuestionIntent.EXPLAIN,
            embedding_vector=[0.1] * 300,
            keywords=["ì„ í˜¸ë„", "ë¶„ì„"],
            confidence_score=0.8,
            requires_specific_docs=["PREFERENCE_ANALYSIS"]
        )
        
        context = await context_builder.build_context(processed_question, "test_user")
        
        # Mock Gemini response with specific preference data
        mock_response = "ë‹¹ì‹ ì˜ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼, ì°½ì˜ì  í™œë™ì´ 1ìœ„ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì‘ë‹µë¥ ì€ 95%ë¡œ ë§¤ìš° ë†’ì•„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ì…ë‹ˆë‹¤."
        response_generator._call_gemini_api.return_value = mock_response
        
        # Generate response
        result = await response_generator.generate_response(context, "test_user")
        
        # Should not add disclaimers for complete data
        assert "âš ï¸ ì°¸ê³ " not in result.content
        assert "ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„" not in result.content
        assert result.quality_score in [ResponseQuality.GOOD, ResponseQuality.EXCELLENT]

    @pytest.mark.asyncio
    async def test_preference_response_validation_missing_data(self, response_generator, context_builder, mock_vector_search):
        """Test response validation when preference data is missing."""
        # Setup missing preference context
        personality_doc = ChatDocument(
            doc_id=uuid4(),
            user_id=uuid4(),
            doc_type="PERSONALITY_PROFILE",
            content={"primary_tendency": {"name": "ì°½ì˜í˜•"}},
            summary_text="ì„±ê²© ë¶„ì„ ê²°ê³¼",
            metadata={},
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        mock_vector_search.similarity_search.return_value = [
            SearchResult(document=personality_doc, similarity_score=0.6, rank=1, search_metadata={})
        ]
        
        processed_question = ProcessedQuestion(
            original_text="ë‚´ ì„ í˜¸ë„ 1ìœ„ê°€ ë­ì•¼?",
            cleaned_text="ë‚´ ì„ í˜¸ë„ 1ìœ„ê°€ ë­ì•¼?",
            category=QuestionCategory.PREFERENCE_ANALYSIS,
            intent=QuestionIntent.EXPLAIN,
            embedding_vector=[0.1] * 300,
            keywords=["ì„ í˜¸ë„"],
            confidence_score=0.8,
            requires_specific_docs=["PREFERENCE_ANALYSIS"]
        )
        
        context = await context_builder.build_context(processed_question, "test_user")
        
        # Mock Gemini response that might hallucinate specific data
        mock_response = "ë‹¹ì‹ ì˜ ì„ í˜¸ë„ 1ìœ„ëŠ” ì°½ì˜ì  í™œë™ì…ë‹ˆë‹¤. ì„ í˜¸ë„ ì ìˆ˜ëŠ” 85ì ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤."
        response_generator._call_gemini_api.return_value = mock_response
        
        # Generate response
        result = await response_generator.generate_response(context, "test_user")
        
        # Should add disclaimer for missing data
        assert ("âš ï¸ ì°¸ê³ " in result.content or 
                "ë°ì´í„°ê°€ í˜„ì¬ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŒ" in result.content or
                "ëŒ€ì•ˆ ë¶„ì„ ë°©ë²•" in result.content)

    @pytest.mark.asyncio
    async def test_preference_response_with_alternatives(self, response_generator, context_builder, mock_vector_search):
        """Test that responses include alternatives when preference data is missing."""
        # Setup context with no preference documents
        mock_vector_search.similarity_search.return_value = []
        
        processed_question = ProcessedQuestion(
            original_text="ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” í™œë™ì´ ë­ì•¼?",
            cleaned_text="ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” í™œë™ì´ ë­ì•¼?",
            category=QuestionCategory.PREFERENCE_ANALYSIS,
            intent=QuestionIntent.EXPLAIN,
            embedding_vector=[0.1] * 300,
            keywords=["ì¢‹ì•„í•˜ëŠ”", "í™œë™"],
            confidence_score=0.8,
            requires_specific_docs=["PREFERENCE_ANALYSIS"]
        )
        
        context = await context_builder.build_context(processed_question, "test_user")
        
        # Mock response
        mock_response = "í˜„ì¬ ì„ í˜¸ë„ ë¶„ì„ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        response_generator._call_gemini_api.return_value = mock_response
        
        # Generate response
        result = await response_generator.generate_response(context, "test_user")
        
        # Should include alternative suggestions
        assert "ğŸ” ëŒ€ì•ˆ ë¶„ì„ ë°©ë²•" in result.content
        assert "ì„±ê²© ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•´" in result.content
        assert "ì‚¬ê³ ëŠ¥ë ¥ ë¶„ì„ì—ì„œ" in result.content

    @pytest.mark.asyncio
    async def test_preference_partial_data_enhancement(self, response_generator, context_builder, mock_vector_search):
        """Test response enhancement for partial preference data."""
        # Setup partial preference context
        partial_doc = self.create_preference_document(
            completion_level="partial",
            content={
                "completion_status": "ë¶€ë¶„ ì™„ë£Œ",
                "preferences": [{"preference_name": "ì°½ì˜ì  í™œë™", "rank": 1}],
                "stats": None,
                "jobs": None
            }
        )
        
        mock_vector_search.similarity_search.return_value = [
            SearchResult(document=partial_doc, similarity_score=0.7, rank=1, search_metadata={})
        ]
        
        processed_question = ProcessedQuestion(
            original_text="ë‚´ ì„ í˜¸ë„ ë¶„ì„í•´ì¤˜",
            cleaned_text="ë‚´ ì„ í˜¸ë„ ë¶„ì„í•´ì¤˜?",
            category=QuestionCategory.PREFERENCE_ANALYSIS,
            intent=QuestionIntent.ANALYZE,
            embedding_vector=[0.1] * 300,
            keywords=["ì„ í˜¸ë„", "ë¶„ì„"],
            confidence_score=0.8,
            requires_specific_docs=["PREFERENCE_ANALYSIS"]
        )
        
        context = await context_builder.build_context(processed_question, "test_user")
        
        # Mock response
        mock_response = "ë¶€ë¶„ì ì¸ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•˜ë©´, ì°½ì˜ì  í™œë™ì— ëŒ€í•œ ì„ í˜¸ê°€ ë†’ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
        response_generator._call_gemini_api.return_value = mock_response
        
        # Generate response
        result = await response_generator.generate_response(context, "test_user")
        
        # Should include enhancement for partial data
        assert ("ğŸ’¡ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ë¥¼ ìœ„í•´" in result.content or 
                "ğŸ’¡ ì™„ì „í•œ ì„ í˜¸ë„ ë¶„ì„ì„ ìœ„í•œ íŒ" in result.content)
        assert ("ë‹¤ë¥¸ ë¶„ì„ ê²°ê³¼ë„ í•¨ê»˜ í™•ì¸" in result.content or
                "ë‹¤ë¥¸ ê²€ì‚¬ ê²°ê³¼(ì„±ê²©, ì‚¬ê³ ëŠ¥ë ¥, ì—­ëŸ‰)ì™€ í•¨ê»˜" in result.content)

    @pytest.mark.asyncio
    async def test_end_to_end_preference_workflow(self, question_processor, context_builder, response_generator, mock_vector_search):
        """Test complete end-to-end workflow for preference questions."""
        # Setup complete preference document
        complete_doc = self.create_preference_document(
            completion_level="complete",
            content={
                "completion_status": "ì™„ë£Œ",
                "preferences": [
                    {"preference_name": "ì°½ì˜ì  í™œë™", "rank": 1, "description": "ì˜ˆìˆ ì  ì°½ì‘ í™œë™ ì„ í˜¸"},
                    {"preference_name": "ë¶„ì„ì  ì‚¬ê³ ", "rank": 2, "description": "ë…¼ë¦¬ì  ë¶„ì„ ì—…ë¬´ ì„ í˜¸"}
                ],
                "stats": {"response_rate": 92, "total_image_count": 50},
                "jobs": [
                    {"job_name": "ë””ìì´ë„ˆ", "preference_match": "ì°½ì˜ì  í™œë™"},
                    {"job_name": "ë°ì´í„° ë¶„ì„ê°€", "preference_match": "ë¶„ì„ì  ì‚¬ê³ "}
                ]
            }
        )
        
        mock_vector_search.similarity_search.return_value = [
            SearchResult(document=complete_doc, similarity_score=0.9, rank=1, search_metadata={})
        ]
        
        # Step 1: Process question
        question = "ë‚´ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ì™€ ì¶”ì²œ ì§ì—… ì•Œë ¤ì¤˜"
        processed_question = await question_processor.process_question(question, "test_user")
        
        assert processed_question.category == QuestionCategory.PREFERENCE_ANALYSIS
        assert processed_question.intent in [QuestionIntent.EXPLAIN, QuestionIntent.RECOMMEND]
        
        # Step 2: Build context
        context = await context_builder.build_context(processed_question, "test_user")
        
        assert context.prompt_template == PromptTemplate.PREFERENCE_EXPLAIN
        assert len(context.retrieved_documents) == 1
        assert "ì„ í˜¸ë„ ë¶„ì„ ì „ë¬¸ê°€" in context.formatted_prompt
        
        # Step 3: Generate response
        mock_response = "ë¶„ì„ ê²°ê³¼ ì°½ì˜ì  í™œë™(1ìœ„)ê³¼ ë¶„ì„ì  ì‚¬ê³ (2ìœ„)ì— ëŒ€í•œ ì„ í˜¸ê°€ ë†’ìŠµë‹ˆë‹¤. ì¶”ì²œ ì§ì—…ìœ¼ë¡œëŠ” ë””ìì´ë„ˆì™€ ë°ì´í„° ë¶„ì„ê°€ê°€ ìˆìŠµë‹ˆë‹¤."
        response_generator._call_gemini_api.return_value = mock_response
        
        result = await response_generator.generate_response(context, "test_user")
        
        # Verify final result
        assert result.quality_score in [ResponseQuality.GOOD, ResponseQuality.EXCELLENT]
        assert result.confidence_score > 0.7
        assert "ì°½ì˜ì  í™œë™" in result.content
        assert "ë¶„ì„ì  ì‚¬ê³ " in result.content
        assert len(result.retrieved_doc_ids) == 1

    @pytest.mark.asyncio
    async def test_preference_question_with_follow_up_context(self, question_processor, context_builder, mock_vector_search):
        """Test preference questions with follow-up context."""
        # Setup preference document
        pref_doc = self.create_preference_document()
        mock_vector_search.similarity_search.return_value = [
            SearchResult(document=pref_doc, similarity_score=0.8, rank=1, search_metadata={})
        ]
        
        # First question
        first_question = await question_processor.process_question("ë‚´ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ ì•Œë ¤ì¤˜", "test_user")
        
        # Follow-up question
        follow_up_question = await question_processor.process_question("ê·¸ëŸ¼ ì¶”ì²œ ì§ì—…ì€ ë­ì•¼?", "test_user")
        
        # Build context with previous context
        context = await context_builder.build_context(
            follow_up_question, 
            "test_user", 
            previous_context="ì´ì „ì— ì„ í˜¸ë„ ë¶„ì„ì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤."
        )
        
        # Should handle follow-up appropriately - either as follow-up or career recommendation with context
        assert ("ì´ì „ ë§¥ë½" in context.formatted_prompt or 
                context.prompt_template == PromptTemplate.FOLLOW_UP or
                (context.prompt_template == PromptTemplate.CAREER_RECOMMEND and context.context_metadata["has_previous_context"]))


if __name__ == "__main__":
    pytest.main([__file__, "-v"])