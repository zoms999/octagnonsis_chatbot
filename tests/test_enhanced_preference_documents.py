"""
Unit tests for enhanced preference document creation with missing data scenarios
Tests the new informative document templates and fallback logic
"""

import pytest
from datetime import datetime
from unittest.mock import patch
from etl.document_transformer import DocumentTransformer, TransformedDocument


class TestEnhancedPreferenceDocuments:
    """Test suite for enhanced preference document creation with missing data scenarios"""
    
    def setup_method(self):
        """Set up test fixtures"""
        self.transformer = DocumentTransformer()
    
    def test_complete_preference_data_with_summary(self):
        """Test document creation with complete preference data including summary document"""
        query_results = {
            "imagePreferenceStatsQuery": [{
                "total_image_count": 120,
                "response_count": 108,
                "response_rate": 90
            }],
            "preferenceDataQuery": [
                {
                    "preference_name": "ì‹¤ë‚´ í™œë™ ì„ í˜¸",
                    "question_count": 15,
                    "response_rate": 85,
                    "rank": 1,
                    "description": "ì¡°ìš©í•˜ê³  ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì„ í˜¸í•©ë‹ˆë‹¤."
                },
                {
                    "preference_name": "ì°½ì˜ì  í™œë™ ì„ í˜¸", 
                    "question_count": 12,
                    "response_rate": 78,
                    "rank": 2,
                    "description": "ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” í™œë™ì„ ì¢‹ì•„í•©ë‹ˆë‹¤."
                }
            ],
            "preferenceJobsQuery": [
                {
                    "preference_name": "ì‹¤ë‚´ í™œë™ ì„ í˜¸",
                    "preference_type": "rimg1",
                    "jo_name": "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì",
                    "jo_outline": "ì»´í“¨í„° í”„ë¡œê·¸ë¨ ê°œë°œ",
                    "jo_mainbusiness": "ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ê³„ ë° ê°œë°œ",
                    "majors": "ì»´í“¨í„°ê³µí•™, ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™"
                }
            ]
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Should create completion summary + stats + preferences overview + individual prefs + jobs overview + job details
        assert len(documents) >= 6
        
        # Check completion summary document
        summary_docs = [d for d in documents if d.metadata.get("sub_type") == "completion_summary"]
        assert len(summary_docs) == 1
        summary_doc = summary_docs[0]
        assert summary_doc.content["completion_status"] == "ì™„ë£Œ"
        assert summary_doc.content["response_rate"] == 90
        assert summary_doc.content["preference_count"] == 2
        assert summary_doc.content["job_count"] == 1
        assert "quality_score" in summary_doc.content
        assert summary_doc.metadata["completion_level"] == "complete"

    def test_no_preference_data_comprehensive_fallback(self):
        """Test comprehensive fallback document when no preference data is available"""
        query_results = {
            "imagePreferenceStatsQuery": [],
            "preferenceDataQuery": [],
            "preferenceJobsQuery": []
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Should create single comprehensive fallback document
        assert len(documents) == 1
        
        fallback_doc = documents[0]
        assert fallback_doc.metadata["sub_type"] == "unavailable"
        assert fallback_doc.metadata["completion_level"] == "none"
        assert fallback_doc.metadata["missing_count"] == 3
        
        # Check enhanced content structure
        content = fallback_doc.content
        assert "missing_components" in content
        assert "explanation" in content
        assert "alternatives" in content
        assert "recommendation" in content
        assert "data_availability" in content
        assert "next_steps" in content
        
        # Check that all components are marked as missing
        assert len(content["missing_components"]) == 3
        assert "ì´ë¯¸ì§€ ì„ í˜¸ë„ ê²€ì‚¬ í†µê³„" in content["missing_components"]
        assert "ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼" in content["missing_components"]
        assert "ì„ í˜¸ë„ ê¸°ë°˜ ì§ì—… ì¶”ì²œ" in content["missing_components"]
        
        # Check data availability assessment
        availability = content["data_availability"]
        assert availability["ê²€ì‚¬_í†µê³„"] == "ì²˜ë¦¬ ì¤‘"
        assert availability["ì„ í˜¸ë„_ë¶„ì„"] == "ì²˜ë¦¬ ì¤‘"
        assert availability["ì§ì—…_ì¶”ì²œ"] == "ì²˜ë¦¬ ì¤‘"
        
        # Check next steps are provided
        assert isinstance(content["next_steps"], list)
        assert len(content["next_steps"]) > 0

    def test_partial_preference_data_with_partial_document(self):
        """Test partial document creation when some preference data is available"""
        query_results = {
            "imagePreferenceStatsQuery": [{
                "total_image_count": 120,
                "response_count": 96,
                "response_rate": 80
            }],
            "preferenceDataQuery": [
                {
                    "preference_name": "ì‹¤ë‚´ í™œë™ ì„ í˜¸",
                    "rank": 1,
                    "response_rate": 85,
                    "description": "ì¡°ìš©í•œ í™˜ê²½ ì„ í˜¸"
                }
            ],
            "preferenceJobsQuery": []  # Missing jobs data
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Should create partial document + available data documents
        assert len(documents) >= 3  # partial + stats + preferences overview + individual pref
        
        # Check partial document
        partial_docs = [d for d in documents if d.metadata.get("sub_type") == "partial_available"]
        assert len(partial_docs) == 1
        partial_doc = partial_docs[0]
        
        assert partial_doc.content["status"] == "ë¶€ë¶„ ì™„ë£Œ"
        assert partial_doc.content["completion_percentage"] == (2/3) * 100  # 2 out of 3 available
        assert len(partial_doc.content["available_components"]) == 2
        assert len(partial_doc.content["missing_components"]) == 1
        assert "ì„ í˜¸ë„ ê¸°ë°˜ ì§ì—… ì¶”ì²œ" in partial_doc.content["missing_components"]
        
        # Check metadata
        assert partial_doc.metadata["completion_level"] == "partial"
        assert partial_doc.metadata["available_count"] == 2
        assert partial_doc.metadata["missing_count"] == 1

    def test_enhanced_stats_document_with_detailed_interpretation(self):
        """Test enhanced stats document with detailed interpretation and recommendations"""
        query_results = {
            "imagePreferenceStatsQuery": [{
                "total_image_count": 120,
                "response_count": 108,
                "response_rate": 90
            }],
            "preferenceDataQuery": [],
            "preferenceJobsQuery": []
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Find stats document
        stats_docs = [d for d in documents if d.metadata.get("sub_type") == "test_stats"]
        assert len(stats_docs) == 1
        stats_doc = stats_docs[0]
        
        # Check enhanced content
        content = stats_doc.content
        assert "interpretation" in content
        assert "recommendations" in content
        assert "quality_indicator" in content
        assert "next_steps" in content
        
        # Check high response rate interpretation
        assert "ë§¤ìš° ì¶©ì‹¤íˆ ì™„ë£Œ" in content["interpretation"]
        assert "ğŸŸ¢ ë§¤ìš° ë†’ìŒ" == content["quality_indicator"]
        
        # Check recommendations are provided
        assert isinstance(content["recommendations"], list)
        assert len(content["recommendations"]) > 0
        
        # Check next steps are provided
        assert isinstance(content["next_steps"], list)
        assert len(content["next_steps"]) > 0

    def test_enhanced_preference_data_documents_with_insights(self):
        """Test enhanced preference data documents with insights and career implications"""
        query_results = {
            "imagePreferenceStatsQuery": [],
            "preferenceDataQuery": [
                {
                    "preference_name": "ì‹¤ë‚´ í™œë™ ì„ í˜¸",
                    "rank": 1,
                    "response_rate": 85,
                    "description": "ì¡°ìš©í•˜ê³  ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì„ í˜¸í•©ë‹ˆë‹¤."
                },
                {
                    "preference_name": "ì°½ì˜ì  í™œë™ ì„ í˜¸",
                    "rank": 2,
                    "response_rate": 78,
                    "description": "ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” í™œë™ì„ ì¢‹ì•„í•©ë‹ˆë‹¤."
                }
            ],
            "preferenceJobsQuery": []
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Find preferences overview document
        overview_docs = [d for d in documents if d.metadata.get("sub_type") == "preferences_overview"]
        assert len(overview_docs) == 1
        overview_doc = overview_docs[0]
        
        # Check enhanced overview content
        content = overview_doc.content
        assert "insights" in content
        assert "preference_distribution" in content
        assert "recommendations" in content
        
        # Check insights are generated
        assert isinstance(content["insights"], list)
        assert len(content["insights"]) > 0
        
        # Check preference distribution analysis
        distribution = content["preference_distribution"]
        assert "strong_preferences" in distribution
        assert "concentration_level" in distribution
        
        # Find individual preference documents
        pref_docs = [d for d in documents if d.metadata.get("sub_type", "").startswith("preference_")]
        assert len(pref_docs) == 2
        
        # Check enhanced individual preference content
        rank1_doc = next(d for d in pref_docs if d.content["rank"] == 1)
        content = rank1_doc.content
        assert "career_implications" in content
        assert "development_suggestions" in content
        assert "related_activities" in content
        
        # Check career implications are provided
        assert isinstance(content["career_implications"], list)
        assert len(content["career_implications"]) > 0

    def test_enhanced_job_documents_with_comprehensive_analysis(self):
        """Test enhanced job documents with comprehensive analysis and career paths"""
        query_results = {
            "imagePreferenceStatsQuery": [],
            "preferenceDataQuery": [],
            "preferenceJobsQuery": [
                {
                    "preference_name": "ì‹¤ë‚´ í™œë™ ì„ í˜¸",
                    "preference_type": "rimg1",
                    "jo_name": "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì",
                    "jo_outline": "ì»´í“¨í„° í”„ë¡œê·¸ë¨ ê°œë°œ",
                    "jo_mainbusiness": "ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ê³„ ë° ê°œë°œ",
                    "majors": "ì»´í“¨í„°ê³µí•™, ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™"
                },
                {
                    "preference_name": "ì‹¤ë‚´ í™œë™ ì„ í˜¸",
                    "preference_type": "rimg1",
                    "jo_name": "ë°ì´í„° ë¶„ì„ê°€",
                    "jo_outline": "ë°ì´í„° ë¶„ì„",
                    "jo_mainbusiness": "ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„",
                    "majors": "í†µê³„í•™, ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤"
                }
            ]
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Find jobs overview document
        overview_docs = [d for d in documents if d.metadata.get("sub_type") == "jobs_overview"]
        assert len(overview_docs) == 1
        overview_doc = overview_docs[0]
        
        # Check enhanced overview content
        content = overview_doc.content
        assert "overview_insights" in content
        assert "career_diversity" in content
        assert "recommendations" in content
        
        # Find individual job preference documents
        job_docs = [d for d in documents if d.metadata.get("sub_type", "").startswith("jobs_")]
        job_detail_docs = [d for d in job_docs if d.metadata.get("sub_type") != "jobs_overview"]
        assert len(job_detail_docs) == 1  # One preference type
        
        job_doc = job_detail_docs[0]
        content = job_doc.content
        
        # Check enhanced job content
        assert "career_paths" in content
        assert "industry_analysis" in content
        assert "skill_requirements" in content
        assert "education_recommendations" in content
        assert "next_steps" in content
        
        # Check career paths are suggested
        assert isinstance(content["career_paths"], list)
        
        # Check industry analysis
        industry_analysis = content["industry_analysis"]
        assert "industry_count" in industry_analysis
        assert "industries" in industry_analysis

    def test_quality_score_calculation(self):
        """Test quality score calculation for preference analysis completeness"""
        # Test high quality scenario
        high_score = self.transformer._calculate_preference_quality_score(95, 8, 15)
        assert high_score == 100.0
        
        # Test medium quality scenario
        medium_score = self.transformer._calculate_preference_quality_score(75, 5, 8)
        assert 70 <= medium_score <= 85
        
        # Test low quality scenario
        low_score = self.transformer._calculate_preference_quality_score(30, 2, 3)
        assert low_score <= 50

    def test_missing_data_explanation_generation(self):
        """Test generation of detailed explanations for missing data"""
        # Test all data missing
        all_missing = ["ì´ë¯¸ì§€ ì„ í˜¸ë„ ê²€ì‚¬ í†µê³„", "ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼", "ì„ í˜¸ë„ ê¸°ë°˜ ì§ì—… ì¶”ì²œ"]
        explanation = self.transformer._generate_missing_data_explanation(all_missing)
        assert "ëª¨ë“  ë°ì´í„°ë¥¼ ì´ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in explanation
        assert "ê²€ì‚¬ë¥¼ ì•„ì§ ì‹œì‘í•˜ì§€ ì•Šì•˜ê±°ë‚˜" in explanation
        
        # Test partial data missing
        partial_missing = ["ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼"]
        explanation = self.transformer._generate_missing_data_explanation(partial_missing)
        assert "ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ ë°ì´í„°ë¥¼ ì´ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in explanation
        
        # Test two components missing
        two_missing = ["ì´ë¯¸ì§€ ì„ í˜¸ë„ ê²€ì‚¬ í†µê³„", "ì„ í˜¸ë„ ê¸°ë°˜ ì§ì—… ì¶”ì²œ"]
        explanation = self.transformer._generate_missing_data_explanation(two_missing)
        assert "ë‹¤ìŒ ì„ í˜¸ë„ ë¶„ì„ ë°ì´í„°ë¥¼ ì´ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in explanation

    def test_alternative_suggestions_generation(self):
        """Test generation of alternative test result suggestions"""
        alternatives = self.transformer._generate_alternative_suggestions()
        
        # Check that all major alternative categories are included
        assert "ì„±í–¥ ë¶„ì„" in alternatives
        assert "ì‚¬ê³ ë ¥ ë¶„ì„" in alternatives
        assert "ì—­ëŸ‰ ë¶„ì„" in alternatives
        assert "ì§ì—… ì¶”ì²œ" in alternatives
        assert "í•™ìŠµ ìŠ¤íƒ€ì¼" in alternatives
        
        # Check formatting includes emojis and structure
        assert "ğŸ”" in alternatives
        assert "ğŸ§ " in alternatives
        assert "ğŸ’ª" in alternatives
        assert "ğŸ’¼" in alternatives
        assert "ğŸ“š" in alternatives

    def test_specific_recommendations_generation(self):
        """Test generation of specific recommendations based on missing components"""
        # Test all missing
        all_missing = ["ì´ë¯¸ì§€ ì„ í˜¸ë„ ê²€ì‚¬ í†µê³„", "ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼", "ì„ í˜¸ë„ ê¸°ë°˜ ì§ì—… ì¶”ì²œ"]
        recommendation = self.transformer._generate_specific_recommendations(all_missing)
        assert "ê²€ì‚¬ë¥¼ ì™„ë£Œí•˜ì§€ ì•Šìœ¼ì…¨ë‹¤ë©´" in recommendation
        
        # Test partial missing
        partial_missing = ["ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼", "ì„ í˜¸ë„ ê¸°ë°˜ ì§ì—… ì¶”ì²œ"]
        recommendation = self.transformer._generate_specific_recommendations(partial_missing)
        assert "ì¼ë¶€ ì„ í˜¸ë„ ë°ì´í„°ëŠ” ì²˜ë¦¬ ì¤‘" in recommendation
        
        # Test single missing
        single_missing = ["ì„ í˜¸ë„ ê¸°ë°˜ ì§ì—… ì¶”ì²œ"]
        recommendation = self.transformer._generate_specific_recommendations(single_missing)
        assert "ëŒ€ë¶€ë¶„ì˜ ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼ëŠ” ì´ìš© ê°€ëŠ¥" in recommendation

    def test_data_availability_assessment(self):
        """Test assessment of data availability for each component"""
        available_data = {"stats": True, "preferences": False, "jobs": True}
        assessment = self.transformer._assess_data_availability(available_data)
        
        assert assessment["ê²€ì‚¬_í†µê³„"] == "ì´ìš© ê°€ëŠ¥"
        assert assessment["ì„ í˜¸ë„_ë¶„ì„"] == "ì²˜ë¦¬ ì¤‘"
        assert assessment["ì§ì—…_ì¶”ì²œ"] == "ì´ìš© ê°€ëŠ¥"

    def test_next_steps_suggestions(self):
        """Test generation of specific next steps based on missing data"""
        # Test all missing
        all_missing = ["ì´ë¯¸ì§€ ì„ í˜¸ë„ ê²€ì‚¬ í†µê³„", "ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼", "ì„ í˜¸ë„ ê¸°ë°˜ ì§ì—… ì¶”ì²œ"]
        steps = self.transformer._suggest_next_steps(all_missing)
        assert len(steps) >= 3
        assert any("ê²€ì‚¬ ì™„ë£Œ ì—¬ë¶€ë¥¼ í™•ì¸" in step for step in steps)
        
        # Test stats missing
        stats_missing = ["ì´ë¯¸ì§€ ì„ í˜¸ë„ ê²€ì‚¬ í†µê³„"]
        steps = self.transformer._suggest_next_steps(stats_missing)
        assert any("ì´ìš© ê°€ëŠ¥í•œ ì„ í˜¸ë„ ë¶„ì„" in step for step in steps)

    def test_low_response_rate_handling_enhanced(self):
        """Test enhanced handling of low response rate scenarios"""
        query_results = {
            "imagePreferenceStatsQuery": [{
                "total_image_count": 120,
                "response_count": 24,
                "response_rate": 20
            }],
            "preferenceDataQuery": [],
            "preferenceJobsQuery": []
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Find stats document
        stats_docs = [d for d in documents if d.metadata.get("sub_type") == "test_stats"]
        assert len(stats_docs) == 1
        stats_doc = stats_docs[0]
        
        # Check low response rate handling
        content = stats_doc.content
        assert content["completion_status"] == "ë¯¸ì™„ë£Œ"
        assert content["quality_indicator"] == "ğŸ”´ ë§¤ìš° ë‚®ìŒ"
        assert "ì •í™•íˆ íŒŒì•…í•˜ê¸° ì–´ë ¤ìš°ë©°" in content["interpretation"]
        
        # Check recommendations focus on completing the test
        recommendations = content["recommendations"]
        assert any("ê²€ì‚¬ë¥¼ ë” ì™„ë£Œ" in rec for rec in recommendations)

    @patch('etl.document_transformer.datetime')
    def test_metadata_consistency_enhanced(self, mock_datetime):
        """Test that all enhanced documents have consistent metadata structure"""
        mock_datetime.now.return_value.isoformat.return_value = "2024-01-01T12:00:00"
        
        query_results = {
            "imagePreferenceStatsQuery": [{
                "total_image_count": 120,
                "response_count": 96,
                "response_rate": 80
            }],
            "preferenceDataQuery": [
                {
                    "preference_name": "ì‹¤ë‚´ í™œë™ ì„ í˜¸",
                    "rank": 1,
                    "response_rate": 85
                }
            ],
            "preferenceJobsQuery": [
                {
                    "preference_name": "ì‹¤ë‚´ í™œë™ ì„ í˜¸",
                    "jo_name": "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì"
                }
            ]
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Check all documents have required metadata
        for doc in documents:
            assert "data_sources" in doc.metadata
            assert "created_at" in doc.metadata
            assert "sub_type" in doc.metadata
            assert "completion_level" in doc.metadata
            assert doc.metadata["created_at"] == "2024-01-01T12:00:00"
            assert doc.doc_type == "PREFERENCE_ANALYSIS"
            
            # Check enhanced metadata fields based on document type
            if doc.metadata["sub_type"] == "completion_summary":
                assert "quality_score" in doc.metadata
            elif doc.metadata["sub_type"] == "test_stats":
                assert "response_rate" in doc.metadata
            elif doc.metadata["sub_type"] == "partial_available":
                assert "available_count" in doc.metadata
                assert "missing_count" in doc.metadata

    def test_malformed_data_resilience_enhanced(self):
        """Test enhanced resilience to malformed preference data"""
        query_results = {
            "imagePreferenceStatsQuery": [{}],  # Empty stats
            "preferenceDataQuery": [
                {"preference_name": None},  # None name
                {"preference_name": ""},    # Empty name
                None,                       # None object
                {"preference_name": "Valid Preference", "rank": 1}  # Valid data
            ],
            "preferenceJobsQuery": [
                {"jo_name": "Developer"},   # Missing preference_name
                None,                       # None object
                {"preference_name": "Valid", "jo_name": "Designer"}  # Valid data
            ]
        }
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Should handle gracefully and create appropriate documents
        assert len(documents) >= 1
        
        # Should create partial document since some data is available
        partial_docs = [d for d in documents if d.metadata.get("sub_type") == "partial_available"]
        assert len(partial_docs) == 1
        
        # Should filter out invalid preference data but keep valid ones
        pref_docs = [d for d in documents if d.metadata.get("sub_type", "").startswith("preference_")]
        assert len(pref_docs) == 1  # Only the valid preference should create a document

    def test_edge_case_empty_query_results(self):
        """Test handling of completely empty query results"""
        query_results = {}
        
        documents = self.transformer._chunk_preference_analysis(query_results)
        
        # Should create fallback document
        assert len(documents) == 1
        assert documents[0].metadata["sub_type"] == "unavailable"
        assert documents[0].metadata["completion_level"] == "none"
        assert documents[0].metadata["missing_count"] == 3