"""
Unit tests for anti-hallucination measures in response generator.

Tests the response generator's ability to validate preference data availability,
detect hallucination patterns, and provide appropriate disclaimers and alternatives.
"""

import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch
from uuid import uuid4
from datetime import datetime
import json

from rag.response_generator import ResponseGenerator, GeneratedResponse, ResponseQuality
from rag.context_builder import ConstructedContext, PromptTemplate, RetrievedDocument
from database.models import ChatDocument


class TestResponseGeneratorAntiHallucination:
    """Test anti-hallucination measures in response generator."""
    
    @pytest.fixture
    def response_generator(self):
        """Response generator instance for testing."""
        with patch.dict('os.environ', {'GEMINI_API_KEY': 'test-key'}):
            generator = ResponseGenerator()
            # Mock the Gemini API call
            generator._call_gemini_api = AsyncMock()
            return generator
    
    def create_preference_document(self, completion_level="complete", content=None, metadata=None):
        """Helper to create preference documents for testing."""
        if content is None:
            if completion_level == "complete":
                content = {
                    "completion_status": "ì™„ë£Œ",
                    "preferences": [
                        {"preference_name": "ì°½ì˜ì  í™œë™", "rank": 1, "score": 85},
                        {"preference_name": "ë¶„ì„ì  ì‚¬ê³ ", "rank": 2, "score": 78}
                    ],
                    "stats": {"response_rate": 95, "total_image_count": 50},
                    "jobs": [{"job_name": "ë””ìì´ë„ˆ", "match_score": 90}]
                }
            elif completion_level == "partial":
                content = {
                    "completion_status": "ë¶€ë¶„ ì™„ë£Œ",
                    "preferences": [{"preference_name": "ì°½ì˜ì  í™œë™", "rank": 1}],
                    "stats": None,
                    "jobs": None
                }
            else:  # missing
                content = {"message": "ì„ í˜¸ë„ ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        if metadata is None:
            metadata = {"completion_level": completion_level}
        
        return ChatDocument(
            doc_id=uuid4(),
            user_id=uuid4(),
            doc_type="PREFERENCE_ANALYSIS",
            content=content,
            summary_text="ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼",
            metadata=metadata,
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
    
    def create_constructed_context(self, template=PromptTemplate.PREFERENCE_EXPLAIN, 
                                 question="ë‚´ ì„ í˜¸ë„ ì•Œë ¤ì¤˜", documents=None):
        """Helper to create constructed context for testing."""
        if documents is None:
            documents = []
        
        retrieved_docs = [
            RetrievedDocument(
                document=doc,
                similarity_score=0.8,
                relevance_score=0.9,
                content_summary=doc.summary_text,
                key_points=["ì„ í˜¸ë„ ë¶„ì„"]
            ) for doc in documents
        ]
        
        return ConstructedContext(
            user_question=question,
            retrieved_documents=retrieved_docs,
            prompt_template=template,
            formatted_prompt=f"ì‚¬ìš©ì ì§ˆë¬¸: {question}",
            context_metadata={},
            token_count_estimate=100
        )

    def test_validate_preference_data_availability_complete(self, response_generator):
        """Test preference data availability validation with complete data."""
        complete_doc = self.create_preference_document(completion_level="complete")
        context = self.create_constructed_context(documents=[complete_doc])
        
        result = response_generator._validate_preference_data_availability(context)
        
        assert result["has_preference_docs"] is True
        assert result["completion_level"] == "complete"
        assert result["data_quality"] == "high"
        assert "stats" in result["available_components"]
        assert "preferences" in result["available_components"]
        assert "jobs" in result["available_components"]
        assert len(result["missing_components"]) == 0

    def test_validate_preference_data_availability_partial(self, response_generator):
        """Test preference data availability validation with partial data."""
        partial_doc = self.create_preference_document(completion_level="partial")
        context = self.create_constructed_context(documents=[partial_doc])
        
        result = response_generator._validate_preference_data_availability(context)
        
        assert result["has_preference_docs"] is True
        assert result["completion_level"] == "partial"
        assert result["data_quality"] in ["low", "medium"]
        assert "preferences" in result["available_components"]
        assert "stats" in result["missing_components"]
        assert "jobs" in result["missing_components"]

    def test_validate_preference_data_availability_missing(self, response_generator):
        """Test preference data availability validation with missing data."""
        context = self.create_constructed_context(documents=[])  # No preference documents
        
        result = response_generator._validate_preference_data_availability(context)
        
        assert result["has_preference_docs"] is False
        assert result["completion_level"] == "missing"
        assert result["data_quality"] == "none"
        assert len(result["available_components"]) == 0
        assert "stats" in result["missing_components"]
        assert "preferences" in result["missing_components"]
        assert "jobs" in result["missing_components"]

    def test_detect_hallucination_patterns_specific_data(self, response_generator):
        """Test detection of specific data hallucination patterns."""
        data_availability = {
            "completion_level": "missing",
            "data_quality": "none"
        }
        
        # Response with specific claims that shouldn't exist
        response = "ë‹¹ì‹ ì˜ ì„ í˜¸ë„ 1ìœ„ëŠ” ì°½ì˜ì  í™œë™ì´ê³ , ì‘ë‹µë¥ ì€ 95%ì…ë‹ˆë‹¤. ì„ í˜¸ë„ ì ìˆ˜ëŠ” 85ì ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤."
        
        patterns = response_generator._detect_preference_hallucination_patterns(response, data_availability)
        
        assert len(patterns) > 0
        pattern_types = [p["type"] for p in patterns]
        assert "specific_ranking" in pattern_types
        # The response_rate pattern matches "ì‘ë‹µë¥ ì€ 95%" instead of specific_percentage
        assert "response_rate" in pattern_types or "specific_percentage" in pattern_types
        assert "specific_score" in pattern_types

    def test_detect_hallucination_patterns_definitive_claims(self, response_generator):
        """Test detection of definitive claim patterns."""
        data_availability = {
            "completion_level": "partial",
            "data_quality": "low"
        }
        
        response = "ë‹¹ì‹ ì˜ ì„ í˜¸ë„ëŠ” í™•ì‹¤íˆ ì°½ì˜ì  í™œë™ì…ë‹ˆë‹¤. ê°€ì¥ ì„ í˜¸í•˜ëŠ” ê²ƒì€ ì˜ˆìˆ  ë¶„ì•¼ì…ë‹ˆë‹¤."
        
        patterns = response_generator._detect_preference_hallucination_patterns(response, data_availability)
        
        assert len(patterns) > 0
        pattern_types = [p["type"] for p in patterns]
        assert any("definitive" in ptype or "certainty" in ptype or "absolute" in ptype for ptype in pattern_types)

    def test_generate_data_availability_disclaimer_missing(self, response_generator):
        """Test disclaimer generation for missing data."""
        data_availability = {
            "completion_level": "missing",
            "available_components": [],
            "missing_components": ["stats", "preferences", "jobs"]
        }
        
        detected_patterns = [
            {"type": "specific_ranking", "severity": "high"},
            {"type": "specific_percentage", "severity": "high"}
        ]
        
        disclaimer = response_generator._generate_data_availability_disclaimer(data_availability, detected_patterns)
        
        assert "âš ï¸ ì¤‘ìš”" in disclaimer
        assert "ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„" in disclaimer
        assert "ì¼ë°˜ì ì¸ ê°€ì´ë“œë¼ì¸" in disclaimer

    def test_generate_data_availability_disclaimer_partial(self, response_generator):
        """Test disclaimer generation for partial data."""
        data_availability = {
            "completion_level": "partial",
            "available_components": ["preferences"],
            "missing_components": ["stats", "jobs"]
        }
        
        detected_patterns = [
            {"type": "definitive_claim", "severity": "high"}
        ]
        
        disclaimer = response_generator._generate_data_availability_disclaimer(data_availability, detected_patterns)
        
        assert "ğŸ’¡ ë°ì´í„° ìƒíƒœ ì•ˆë‚´" in disclaimer
        assert "preferences" in disclaimer
        assert "stats, jobs" in disclaimer

    def test_validate_preference_response_with_complete_data(self, response_generator):
        """Test preference response validation with complete data (should not add disclaimers)."""
        complete_doc = self.create_preference_document(completion_level="complete")
        context = self.create_constructed_context(
            template=PromptTemplate.PREFERENCE_EXPLAIN,
            documents=[complete_doc]
        )
        
        response = "ë‹¹ì‹ ì˜ ì„ í˜¸ë„ 1ìœ„ëŠ” ì°½ì˜ì  í™œë™ì´ê³ , ì ìˆ˜ëŠ” 85ì ì…ë‹ˆë‹¤."
        
        validated_response = response_generator._validate_preference_response(response, context)
        
        # Should not add disclaimers for complete data
        assert "âš ï¸" not in validated_response
        assert "ğŸ’¡" not in validated_response
        assert validated_response == response

    def test_validate_preference_response_with_missing_data(self, response_generator):
        """Test preference response validation with missing data (should add disclaimers)."""
        context = self.create_constructed_context(
            template=PromptTemplate.PREFERENCE_MISSING,
            documents=[]  # No preference documents
        )
        
        response = "ë‹¹ì‹ ì˜ ì„ í˜¸ë„ 1ìœ„ëŠ” ì°½ì˜ì  í™œë™ì´ê³ , ì„ í˜¸ë„ ì ìˆ˜ëŠ” 85ì ì…ë‹ˆë‹¤."
        
        validated_response = response_generator._validate_preference_response(response, context)
        
        # Should add disclaimer for missing data with specific claims
        assert "âš ï¸ ì¤‘ìš”" in validated_response
        assert "ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„" in validated_response

    def test_validate_preference_response_non_preference_question(self, response_generator):
        """Test that non-preference questions are not affected by validation."""
        personality_doc = ChatDocument(
            doc_id=uuid4(),
            user_id=uuid4(),
            doc_type="PERSONALITY_PROFILE",
            content={"primary_tendency": {"name": "ì°½ì˜í˜•"}},
            summary_text="ì„±ê²© ë¶„ì„",
            metadata={},
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        context = self.create_constructed_context(
            template=PromptTemplate.PERSONALITY_EXPLAIN,
            question="ë‚´ ì„±ê²©ì€ ì–´ë•Œ?",
            documents=[personality_doc]
        )
        
        response = "ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì„±ê²©ì…ë‹ˆë‹¤."
        
        validated_response = response_generator._validate_preference_response(response, context)
        
        # Should not modify non-preference responses
        assert validated_response == response

    def test_get_preference_acknowledgment_template_missing(self, response_generator):
        """Test acknowledgment template for missing preference data."""
        data_availability = {
            "completion_level": "missing",
            "available_components": []
        }
        
        template = response_generator._get_preference_acknowledgment_template(
            data_availability, "ë‚´ ì„ í˜¸ë„ ì•Œë ¤ì¤˜"
        )
        
        assert "í˜„ì¬ ì„ í˜¸ë„ ë¶„ì„ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in template
        assert "ë‹¤ë¥¸ ê²€ì‚¬ ê²°ê³¼ë¥¼ í†µí•´" in template

    def test_get_preference_acknowledgment_template_partial(self, response_generator):
        """Test acknowledgment template for partial preference data."""
        data_availability = {
            "completion_level": "partial",
            "available_components": ["preferences", "stats"]
        }
        
        template = response_generator._get_preference_acknowledgment_template(
            data_availability, "ë‚´ ì„ í˜¸ë„ ë¶„ì„í•´ì¤˜"
        )
        
        assert "ì„ í˜¸ë„ ìˆœìœ„, í†µê³„ ì •ë³´ëŠ” ì¤€ë¹„ë˜ì–´ ìˆì§€ë§Œ" in template
        assert "ì¼ë¶€ ì„ í˜¸ë„ ë°ì´í„°ê°€ ì•„ì§ ì²˜ë¦¬ ì¤‘" in template

    def test_get_alternative_analysis_suggestions_career_focus(self, response_generator):
        """Test alternative suggestions for career-focused preference questions."""
        suggestions = response_generator._get_alternative_analysis_suggestions(
            "ë‚´ ì„ í˜¸ë„ì— ë§ëŠ” ì§ì—…ì´ ë­ì•¼?"
        )
        
        assert "ğŸ” ëŒ€ì•ˆ ë¶„ì„ ë°©ë²•" in suggestions
        assert "ë‚´ê²Œ ë§ëŠ” ì§ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?" in suggestions
        assert "ì„±ê²© ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•´" in suggestions

    def test_get_alternative_analysis_suggestions_activity_focus(self, response_generator):
        """Test alternative suggestions for activity-focused preference questions."""
        suggestions = response_generator._get_alternative_analysis_suggestions(
            "ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” í™œë™ì´ ë­ì•¼?"
        )
        
        assert "ğŸ” ëŒ€ì•ˆ ë¶„ì„ ë°©ë²•" in suggestions
        assert "ë‚´ ê°•ì ì„ í™œìš©í•  ìˆ˜ ìˆëŠ” í™œë™ì€?" in suggestions
        assert "ì–´ë–¤ ì·¨ë¯¸ê°€ ë‚˜ì—ê²Œ ë§ì„ê¹Œìš”?" in suggestions

    def test_generate_preference_focused_fallback_with_personality_docs(self, response_generator):
        """Test preference-focused fallback when personality documents are available."""
        personality_doc = ChatDocument(
            doc_id=uuid4(),
            user_id=uuid4(),
            doc_type="PERSONALITY_PROFILE",
            content={"primary_tendency": {"name": "ì°½ì˜í˜•"}},
            summary_text="ì„±ê²© ë¶„ì„",
            metadata={},
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        context = self.create_constructed_context(
            question="ë‚´ ì„ í˜¸ë„ ì•Œë ¤ì¤˜",
            documents=[personality_doc]
        )
        
        fallback = response_generator._generate_preference_focused_fallback(context)
        
        assert "í˜„ì¬ ì„ í˜¸ë„ ë¶„ì„ ë°ì´í„°ì— ì ‘ê·¼í•  ìˆ˜ ì—†ì§€ë§Œ" in fallback
        assert "ì„±ê²© ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•´" in fallback
        assert "ë‚´ ì„±ê²©ì— ë§ëŠ” í™œë™ì€ ë¬´ì—‡ì¸ê°€ìš”?" in fallback

    def test_generate_preference_focused_fallback_with_no_docs(self, response_generator):
        """Test preference-focused fallback when no documents are available."""
        context = self.create_constructed_context(
            question="ë‚´ ì„ í˜¸ë„ ì•Œë ¤ì¤˜",
            documents=[]
        )
        
        fallback = response_generator._generate_preference_focused_fallback(context)
        
        assert "í˜„ì¬ ì„ í˜¸ë„ ë¶„ì„ ë°ì´í„°ì— ì ‘ê·¼í•  ìˆ˜ ì—†ì§€ë§Œ" in fallback
        assert "ë‹¤ë¥¸ ê²€ì‚¬ ê²°ê³¼ê°€ ì¤€ë¹„ë˜ë©´" in fallback
        assert "ì ì„±ê²€ì‚¬ë¥¼ ì™„ë£Œí•˜ì…¨ëŠ”ì§€ í™•ì¸" in fallback

    @pytest.mark.asyncio
    async def test_enhance_with_preference_alternatives_missing_data(self, response_generator):
        """Test enhancement with alternatives for missing preference data."""
        context = self.create_constructed_context(
            template=PromptTemplate.PREFERENCE_MISSING,
            question="ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” í™œë™ì´ ë­ì•¼?",
            documents=[]
        )
        
        response = "í˜„ì¬ ì„ í˜¸ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        enhanced = await response_generator._enhance_with_preference_alternatives(response, context)
        
        assert "ğŸ” ëŒ€ì•ˆ ë¶„ì„ ë°©ë²•" in enhanced
        assert "ë‚´ ê°•ì ì„ í™œìš©í•  ìˆ˜ ìˆëŠ” í™œë™ì€?" in enhanced
        assert "ì–´ë–¤ ì·¨ë¯¸ê°€ ë‚˜ì—ê²Œ ë§ì„ê¹Œìš”?" in enhanced

    @pytest.mark.asyncio
    async def test_enhance_with_preference_alternatives_partial_data(self, response_generator):
        """Test enhancement with alternatives for partial preference data."""
        partial_doc = self.create_preference_document(completion_level="partial")
        context = self.create_constructed_context(
            template=PromptTemplate.PREFERENCE_PARTIAL,
            documents=[partial_doc]
        )
        
        response = "ë¶€ë¶„ì ì¸ ì„ í˜¸ë„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤."
        
        enhanced = await response_generator._enhance_with_preference_alternatives(response, context)
        
        assert "ğŸ’¡ ì™„ì „í•œ ì„ í˜¸ë„ ë¶„ì„ì„ ìœ„í•œ íŒ" in enhanced
        assert "ë‹¤ë¥¸ ê²€ì‚¬ ê²°ê³¼(ì„±ê²©, ì‚¬ê³ ëŠ¥ë ¥, ì—­ëŸ‰)ì™€ í•¨ê»˜" in enhanced
        assert "í˜„ì¬ ê²°ê³¼ë§Œìœ¼ë¡œë„ ì˜ë¯¸ ìˆëŠ” ì¸ì‚¬ì´íŠ¸" in enhanced

    @pytest.mark.asyncio
    async def test_generate_response_with_missing_preference_data_early_return(self, response_generator):
        """Test that generate_response returns early for missing preference data."""
        context = self.create_constructed_context(
            template=PromptTemplate.PREFERENCE_EXPLAIN,  # Not PREFERENCE_MISSING
            question="ë‚´ ì„ í˜¸ë„ 1ìœ„ê°€ ë­ì•¼?",
            documents=[]  # No preference documents
        )
        
        # Should return early without calling Gemini API
        result = await response_generator.generate_response(context, "test_user")
        
        assert result.quality_score == ResponseQuality.ACCEPTABLE
        assert result.confidence_score == 0.6
        assert "í˜„ì¬ ì„ í˜¸ë„ ë¶„ì„ ë°ì´í„°ì— ì ‘ê·¼í•  ìˆ˜ ì—†ì§€ë§Œ" in result.content
        # Verify Gemini API was not called
        response_generator._call_gemini_api.assert_not_called()

    @pytest.mark.asyncio
    async def test_generate_response_with_complete_preference_data(self, response_generator):
        """Test normal response generation with complete preference data."""
        complete_doc = self.create_preference_document(completion_level="complete")
        context = self.create_constructed_context(
            template=PromptTemplate.PREFERENCE_EXPLAIN,
            documents=[complete_doc]
        )
        
        # Mock Gemini response
        mock_response = "ë‹¹ì‹ ì˜ ì„ í˜¸ë„ 1ìœ„ëŠ” ì°½ì˜ì  í™œë™ì…ë‹ˆë‹¤."
        response_generator._call_gemini_api.return_value = mock_response
        
        result = await response_generator.generate_response(context, "test_user")
        
        # Should proceed normally and call Gemini API
        response_generator._call_gemini_api.assert_called_once()
        assert result.quality_score in [ResponseQuality.GOOD, ResponseQuality.EXCELLENT, ResponseQuality.ACCEPTABLE]
        assert "ì°½ì˜ì  í™œë™" in result.content

    def test_extract_topic_from_question_preference(self, response_generator):
        """Test that preference-related questions are correctly identified."""
        test_cases = [
            ("ë‚´ ì„ í˜¸ë„ ì•Œë ¤ì¤˜", "preference"),
            ("ì´ë¯¸ì§€ ì„ í˜¸ë„ëŠ” ì–´ë–»ê²Œ ë‚˜ì™”ì–´?", "preference"),
            ("ë‚˜ëŠ” ë­˜ ì¢‹ì•„í•´?", "preference"),
            ("ë‚´ ê´€ì‹¬ì‚¬ê°€ ë­ì•¼?", "preference"),
            ("ì·¨í–¥ ë¶„ì„ ê²°ê³¼ ë³´ì—¬ì¤˜", "preference"),
            ("ë‚´ ì„±ê²©ì€ ì–´ë•Œ?", "personality"),  # Should not be preference
            ("ì¶”ì²œ ì§ì—…ì´ ë­ì•¼?", "career"),  # Should not be preference
        ]
        
        for question, expected_topic in test_cases:
            topic = response_generator._extract_topic_from_question(question)
            assert topic == expected_topic, f"Question '{question}' should be topic '{expected_topic}', got '{topic}'"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])