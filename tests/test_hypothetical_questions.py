#!/usr/bin/env python3
"""
Test hypothetical questions generation and RAG optimization
"""

import asyncio
import sys
sys.path.append('.')
from etl.legacy_query_executor import LegacyQueryExecutor
from etl.document_transformer import DocumentTransformer
from database.repositories import save_chunked_documents
from database.connection import db_manager

async def test_hypothetical_questions():
    """ê°€ìƒ ì§ˆë¬¸ ìƒì„± ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    
    user_id = "9b08ed21-fddf-4998-a1f4-29bccda89a54"  # ê¸°ì¡´ ì‚¬ìš©ì
    anp_seq = 18223
    
    print(f"ê°€ìƒ ì§ˆë¬¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘:")
    print(f"  User ID: {user_id}")
    print(f"  ANP Seq: {anp_seq}")
    
    try:
        # 1. ì¿¼ë¦¬ ì‹¤í–‰
        executor = LegacyQueryExecutor()
        async with db_manager.get_async_session() as session:
            results = await executor.execute_all_queries_async(session, anp_seq)
            
            successful_results = await executor.get_successful_results(results)
            print(f"âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ: {len(successful_results)}ê°œ ì¿¼ë¦¬")
            
            # 2. ë¬¸ì„œ ë³€í™˜ (ê°€ìƒ ì§ˆë¬¸ ìƒì„± í¬í•¨)
            transformer = DocumentTransformer()
            transformed_docs = await transformer.transform_all_documents(successful_results)
            print(f"âœ… ë¬¸ì„œ ë³€í™˜ ì™„ë£Œ: {len(transformed_docs)}ê°œ ë¬¸ì„œ")
            
            # 3. ê°€ìƒ ì§ˆë¬¸ í™•ì¸
            print("\nğŸ“ ìƒì„±ëœ ê°€ìƒ ì§ˆë¬¸ ìƒ˜í”Œ:")
            for i, doc in enumerate(transformed_docs[:3]):  # ì²˜ìŒ 3ê°œë§Œ í™•ì¸
                print(f"\n  ë¬¸ì„œ {i+1}: {doc.doc_type}")
                print(f"    ìš”ì•½: {doc.summary_text[:50]}...")
                hypothetical_questions = doc.metadata.get('hypothetical_questions', [])
                print(f"    ê°€ìƒ ì§ˆë¬¸ë“¤:")
                for j, question in enumerate(hypothetical_questions, 1):
                    print(f"      {j}. {question}")
                searchable_text = doc.metadata.get('searchable_text', '')
                print(f"    ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ê¸¸ì´: {len(searchable_text)} ë¬¸ì")
            
            # 4. ë¬¸ì„œ ì €ì¥
            await save_chunked_documents(session, user_id, transformed_docs)
            print(f"\nâœ… ë¬¸ì„œ ì €ì¥ ì™„ë£Œ: {len(transformed_docs)}ê°œ ë¬¸ì„œ")
            
            # 5. ì €ì¥ëœ ë¬¸ì„œ í™•ì¸
            from database.models import ChatDocument
            from sqlalchemy import select, func
            
            stmt = select(func.count(ChatDocument.doc_id)).where(ChatDocument.user_id == user_id)
            result = await session.execute(stmt)
            doc_count = result.scalar()
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸: {doc_count}ê°œ ë¬¸ì„œ ì €ì¥ë¨")
            
            # 6. ë©”íƒ€ë°ì´í„° í™•ì¸
            stmt = select(ChatDocument).where(ChatDocument.user_id == user_id).limit(3)
            result = await session.execute(stmt)
            sample_docs = result.scalars().all()
            
            print(f"\nğŸ” ì €ì¥ëœ ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„° ìƒ˜í”Œ:")
            for i, doc in enumerate(sample_docs, 1):
                hypothetical_questions = doc.doc_metadata.get('hypothetical_questions', [])
                print(f"  ë¬¸ì„œ {i}: {doc.doc_type}")
                print(f"    ê°€ìƒ ì§ˆë¬¸ ìˆ˜: {len(hypothetical_questions)}")
                if hypothetical_questions:
                    print(f"    ì²« ë²ˆì§¸ ì§ˆë¬¸: {hypothetical_questions[0]}")
        
        await executor.close()
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_hypothetical_questions())